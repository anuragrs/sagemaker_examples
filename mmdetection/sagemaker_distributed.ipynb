{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training MMDetection Mask-RCNN Model on Sagemaker Distributed Cluster\n",
    "\n",
    "## Motivation\n",
    "[MMDetection](https://github.com/open-mmlab/mmdetection) is a popular open-source Deep Learning framework focused on Computer Vision models and use cases. MMDetection provides to higher level APIs for model training and inference. It demonstrates [state-of-the-art benchmarks](https://github.com/open-mmlab/mmdetection#benchmark-and-model-zoo) for variety of model architecture and extensive Model Zoo.\n",
    "\n",
    "In this notebook, we will build a custom training container with MMdetection library and then train Mask-RCNN model from scratch on [COCO2017 dataset](https://cocodataset.org/#home) using Sagemaker distributed [training feature](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html) in order to reduce training time.\n",
    "\n",
    "### Preconditions\n",
    "- To execute this notebook, you will need to have COCO 2017 training and validation datasets uploaded to S3 bucket available for Amazon Sagemaker service.\n",
    "\n",
    "\n",
    "## Building Training Container\n",
    "\n",
    "Amazon Sagemaker allows to BYO containers for training, data processing, and inference. In our case, we need to build custom training container which will be pushed to your AWS account [ECR service](https://aws.amazon.com/ecr/). \n",
    "\n",
    "For this, we need to login to public ECR with Sagemaker base images and private ECR reposity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3\n",
    "\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "container = \"mzanur-mmdetection-training\" # your container name\n",
    "tag = \"latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "# login to Sagemaker ECR with Deep Learning Containers\n",
    "!aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin 763104351884.dkr.ecr.{region}.amazonaws.com\n",
    "# login to your private ECR\n",
    "!aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account}.dkr.ecr.{region}.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let review training container:\n",
    "- use Sagemaker PyTorch container as base image;\n",
    "- install Pytorch libraries and MMdetection dependencies;\n",
    "- build MMDetection from sources;\n",
    "- configure Sagemaker env variables, specifically, what script to use at training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Build an image of mmdetection that can do distributing training on Amazon Sagemaker \u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# using Sagemaker PyTorch container as base image\u001b[39;49;00m\n",
      "\u001b[37m# from https://github.com/aws/sagemaker-pytorch-container\u001b[39;49;00m\n",
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mUBUNTU\u001b[39;49;00m=\u001b[33m\"16.04\"\u001b[39;49;00m\n",
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mPYTORCH\u001b[39;49;00m=\u001b[33m\"1.6.0\"\u001b[39;49;00m\n",
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mCUDA\u001b[39;49;00m=\u001b[33m\"101\"\u001b[39;49;00m\n",
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mREGION\u001b[39;49;00m=\u001b[33m\"us-east-1\"\u001b[39;49;00m\n",
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33m763104351884.dkr.ecr.${REGION}.amazonaws.com/pytorch-training:${PYTORCH}-gpu-py36-cu${CUDA}-ubuntu${UBUNTU}\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m############# BASIC SETUP ##############\u001b[39;49;00m\n",
      " RUN apt-get update\n",
      " RUN apt-get install -y curl git\n",
      " RUN apt-get update && apt-get install -y ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6 \u001b[33m\\\u001b[39;49;00m\n",
      "    && apt-get clean \u001b[33m\\\u001b[39;49;00m\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "\u001b[37m############# Use pre-built binaries Pytorch default install ############\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install --upgrade \u001b[31mtorchvision\u001b[39;49;00m==\u001b[34m0\u001b[39;49;00m.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
      "\n",
      "\u001b[37m############# mmdetection section ##############\u001b[39;49;00m\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mFORCE_CUDA\u001b[39;49;00m=\u001b[33m\"1\"\u001b[39;49;00m\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mTORCH_CUDA_ARCH_LIST\u001b[39;49;00m=\u001b[33m\"Pascal;Volta;Turing\"\u001b[39;49;00m\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mFVCORE_CACHE\u001b[39;49;00m=\u001b[33m\"/tmp\"\u001b[39;49;00m\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /opt/ml/code\u001b[39;49;00m\n",
      "\u001b[37m# install mmcv full from source to avoid ABI issues\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m git clone https://github.com/open-mmlab/mmcv.git\n",
      "\u001b[34mRUN\u001b[39;49;00m \u001b[36mcd\u001b[39;49;00m mmcv && \u001b[31mMMCV_WITH_OPS\u001b[39;49;00m=\u001b[34m1\u001b[39;49;00m pip install -e .\n",
      "\u001b[34mRUN\u001b[39;49;00m \u001b[36mcd\u001b[39;49;00m ..\n",
      "\u001b[34mRUN\u001b[39;49;00m conda clean --all\n",
      "\u001b[34mRUN\u001b[39;49;00m git clone https://github.com/open-mmlab/mmdetection.git mmdetection\n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPYTHONUNBUFFERED\u001b[39;49;00m=TRUE\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPYTHONDONTWRITEBYTECODE\u001b[39;49;00m=TRUE\n",
      "\u001b[34mENV\u001b[39;49;00m MMDETECTION /opt/ml/code/mmdetection\n",
      "\n",
      "\u001b[34mRUN\u001b[39;49;00m \u001b[36mcd\u001b[39;49;00m mmdetection/ && \u001b[33m\\\u001b[39;49;00m\n",
      "    pip install -r /opt/ml/code/mmdetection/requirements/build.txt && \u001b[33m\\\u001b[39;49;00m\n",
      "    pip install --no-cache-dir -e .\n",
      "\n",
      "\u001b[37m############# SageMaker section ##############\u001b[39;49;00m\n",
      "\u001b[34mCOPY\u001b[39;49;00m container_training/mmdetection_train.py /opt/ml/code\n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      "\u001b[34mENV\u001b[39;49;00m SAGEMAKER_PROGRAM mmdetection_train.py\n",
      "\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "! pygmentize -l docker Dockerfile.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "Next, we build and push custom training container to private ECR\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working in region us-east-1\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  434.7kB\n",
      "Step 1/26 : ARG UBUNTU=\"16.04\"\n",
      "Step 2/26 : ARG PYTORCH=\"1.6.0\"\n",
      "Step 3/26 : ARG CUDA=\"101\"\n",
      "Step 4/26 : ARG REGION=\"us-east-1\"\n",
      "Step 5/26 : FROM 763104351884.dkr.ecr.${REGION}.amazonaws.com/pytorch-training:${PYTORCH}-gpu-py36-cu${CUDA}-ubuntu${UBUNTU}\n",
      " ---> cfe08bbde038\n",
      "Step 6/26 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> 5945d64e7569\n",
      "Step 7/26 : RUN apt-get install -y curl git\n",
      " ---> Using cache\n",
      " ---> c15bb8a2efad\n",
      "Step 8/26 : RUN apt-get update && apt-get install -y ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6     && apt-get clean     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> bd37d7334c4a\n",
      "Step 9/26 : RUN pip install --upgrade torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
      " ---> Using cache\n",
      " ---> ca015ff27008\n",
      "Step 10/26 : ENV FORCE_CUDA=\"1\"\n",
      " ---> Using cache\n",
      " ---> e751cf5de22b\n",
      "Step 11/26 : ENV TORCH_CUDA_ARCH_LIST=\"Pascal;Volta;Turing\"\n",
      " ---> Using cache\n",
      " ---> 700e6359f335\n",
      "Step 12/26 : ENV FVCORE_CACHE=\"/tmp\"\n",
      " ---> Using cache\n",
      " ---> 222753e0c3ff\n",
      "Step 13/26 : WORKDIR /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 4030268442d7\n",
      "Step 14/26 : RUN git clone https://github.com/open-mmlab/mmcv.git\n",
      " ---> Using cache\n",
      " ---> ba573fce1b03\n",
      "Step 15/26 : RUN cd mmcv && MMCV_WITH_OPS=1 pip install -e .\n",
      " ---> Using cache\n",
      " ---> e8de07c8f433\n",
      "Step 16/26 : RUN cd ..\n",
      " ---> Using cache\n",
      " ---> ecde0fe7f30a\n",
      "Step 17/26 : RUN conda clean --all\n",
      " ---> Using cache\n",
      " ---> 8e018a706be5\n",
      "Step 18/26 : RUN git clone https://github.com/open-mmlab/mmdetection.git mmdetection\n",
      " ---> Using cache\n",
      " ---> 2c3ce387a293\n",
      "Step 19/26 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 6a18ad597986\n",
      "Step 20/26 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 802815ce0383\n",
      "Step 21/26 : ENV MMDETECTION /opt/ml/code/mmdetection\n",
      " ---> Using cache\n",
      " ---> 20e00ded70e8\n",
      "Step 22/26 : RUN cd mmdetection/ &&     pip install -r /opt/ml/code/mmdetection/requirements/build.txt &&     pip install --no-cache-dir -e .\n",
      " ---> Using cache\n",
      " ---> 5c4f04617635\n",
      "Step 23/26 : COPY container_training/mmdetection_train.py /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 897bde911b3a\n",
      "Step 24/26 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> f8cf1362cd95\n",
      "Step 25/26 : ENV SAGEMAKER_PROGRAM mmdetection_train.py\n",
      " ---> Using cache\n",
      " ---> bfc9f5e12282\n",
      "Step 26/26 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 8772010992de\n",
      "Successfully built 8772010992de\n",
      "Successfully tagged mzanur-mmdetection-training:latest\n",
      "The push refers to repository [564829616587.dkr.ecr.us-east-1.amazonaws.com/mzanur-mmdetection-training]\n",
      "\n",
      "\u001b[1Bded756f4: Preparing \n",
      "\u001b[1Bae3727ff: Preparing \n",
      "\u001b[1B041dc3ba: Preparing \n",
      "\u001b[1Ba093bbcb: Preparing \n",
      "\u001b[1B867fc66f: Preparing \n",
      "\u001b[1B8ac591fc: Preparing \n",
      "\u001b[1Bd5839f9f: Preparing \n",
      "\u001b[1B487f2ecd: Preparing \n",
      "\u001b[1B9de3d1c7: Preparing \n",
      "\u001b[1Bc54d6636: Preparing \n",
      "\u001b[1Bbf0152ab: Preparing \n",
      "\u001b[1B56e55505: Preparing \n",
      "\u001b[1B73faf040: Preparing \n",
      "\u001b[1B78dab6ea: Preparing \n",
      "\u001b[1Bf1641cb6: Preparing \n",
      "\u001b[11Bac591fc: Waiting g \n",
      "\u001b[1Bcd8033d8: Preparing \n",
      "\u001b[11B87f2ecd: Waiting g \n",
      "\u001b[1B9703999d: Preparing \n",
      "\u001b[10Bf0152ab: Waiting g \n",
      "\u001b[1B45bf29a5: Preparing \n",
      "\u001b[11B6e55505: Waiting g \n",
      "\u001b[10B8dab6ea: Waiting g \n",
      "\u001b[10B1641cb6: Waiting g \n",
      "\u001b[10B9267333: Waiting g \n",
      "\u001b[2B1c273442: Waiting g \n",
      "\u001b[1Bc4b33934: Preparing \n",
      "\u001b[1B3594a68f: Preparing \n",
      "\u001b[1Bff006560: Preparing \n",
      "\u001b[1B7e38f2d8: Preparing \n",
      "\u001b[1B2ea48d23: Preparing \n",
      "\u001b[1B62fe140e: Preparing \n",
      "\u001b[7Bc4b33934: Waiting g \n",
      "\u001b[1Bd96b0113: Preparing \n",
      "\u001b[8B3594a68f: Waiting g \n",
      "\u001b[8Bff006560: Waiting g \n",
      "\u001b[1Bd2b930fc: Preparing \n",
      "\u001b[7B62fe140e: Waiting g \n",
      "\u001b[9B2ea48d23: Waiting g \n",
      "\u001b[1B56d8b3f9: Layer already exists \u001b[35A\u001b[2K\u001b[30A\u001b[2K\u001b[25A\u001b[2K\u001b[17A\u001b[2K\u001b[12A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2Klatest: digest: sha256:cdf812e09ef5c0c082b6233e0ffee330c516090c44fa091ef9f7e4516db11b71 size: 8731\n"
     ]
    }
   ],
   "source": [
    "! ./build_and_push.sh $container $tag Dockerfile.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training script\n",
    "\n",
    "At training time, Sagemaker executes training script defined in `SAGEMAKER_PROGRAM` variable. In our case, this script does following\n",
    "- parses user parameters passed via Sagemaker Hyperparameter dictionary;\n",
    "- based on parameters constructs launch command;\n",
    "- uses `torch.distributed.launch` utility to launch distributed training;\n",
    "- uses MMDetection `tools/train.py` to configure trianing process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ArgumentParser\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmmcv\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Config\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mshutil\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_training_world\u001b[39;49;00m():\n",
      "\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    Calculates number of devices in Sagemaker distributed cluster\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# Get params of Sagemaker distributed cluster from predefined env variables\u001b[39;49;00m\n",
      "    num_gpus = \u001b[36mint\u001b[39;49;00m(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    num_cpus = \u001b[36mint\u001b[39;49;00m(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_CPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    hosts = json.loads(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    current_host = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "    \u001b[37m# Define PyTorch training world\u001b[39;49;00m\n",
      "    world = {}\n",
      "    world[\u001b[33m\"\u001b[39;49;00m\u001b[33mnumber_of_processes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = num_gpus \u001b[34mif\u001b[39;49;00m num_gpus > \u001b[34m0\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m num_cpus\n",
      "    world[\u001b[33m\"\u001b[39;49;00m\u001b[33mnumber_of_machines\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[36mlen\u001b[39;49;00m(hosts)\n",
      "    world[\u001b[33m\"\u001b[39;49;00m\u001b[33msize\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = world[\u001b[33m\"\u001b[39;49;00m\u001b[33mnumber_of_processes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] * world[\u001b[33m\"\u001b[39;49;00m\u001b[33mnumber_of_machines\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    world[\u001b[33m\"\u001b[39;49;00m\u001b[33mmachine_rank\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = hosts.index(current_host)\n",
      "    world[\u001b[33m\"\u001b[39;49;00m\u001b[33mmaster_addr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = hosts[\u001b[34m0\u001b[39;49;00m]\n",
      "    world[\u001b[33m\"\u001b[39;49;00m\u001b[33mmaster_port\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[33m\"\u001b[39;49;00m\u001b[33m55555\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[37m# port is defined by Sagemaker\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m world\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtraining_configurator\u001b[39;49;00m(args, world):\n",
      "    \n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    Configure training process by updating config file: \u001b[39;49;00m\n",
      "\u001b[33m    - takes base config from MMDetection templates;\u001b[39;49;00m\n",
      "\u001b[33m    - updates it with SageMaker specific data locations;\u001b[39;49;00m\n",
      "\u001b[33m    - overrides with user-defined options.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m# updating path to config file inside SM container\u001b[39;49;00m\n",
      "    abs_config_path = os.path.join(\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/code/mmdetection\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, args.config_file)\n",
      "    cfg = Config.fromfile(abs_config_path)\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m args.dataset.lower() == \u001b[33m\"\u001b[39;49;00m\u001b[33mcoco\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "        \n",
      "        cfg.data_root = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] \u001b[37m# By default, data will be download to /opt/ml/input/data/training\u001b[39;49;00m\n",
      "        cfg.data.train.ann_file = os.path.join(cfg.data_root, \u001b[33m\"\u001b[39;49;00m\u001b[33mannotations/instances_train2017.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        cfg.data.train.img_prefix = os.path.join(cfg.data_root, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain2017\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        cfg.data.val.ann_file = os.path.join(cfg.data_root, \u001b[33m\"\u001b[39;49;00m\u001b[33mannotations/instances_val2017.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        cfg.data.val.img_prefix = os.path.join(cfg.data_root, \u001b[33m\"\u001b[39;49;00m\u001b[33mval2017\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \n",
      "        \u001b[37m# Note, that we are using validation dataset for testing purposes\u001b[39;49;00m\n",
      "        cfg.data.test.ann_file = os.path.join(cfg.data_root, \u001b[33m\"\u001b[39;49;00m\u001b[33mannotations/instances_val2017.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        cfg.data.test.img_prefix = os.path.join(cfg.data_root, \u001b[33m\"\u001b[39;49;00m\u001b[33mval2017\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \n",
      "        \u001b[37m# Overriding config with options\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m args.options \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\n",
      "            cfg.merge_from_dict(args.options)\n",
      "        \n",
      "        \u001b[37m# scaling LR based on number of training processes\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m args.auto_scale:\n",
      "            cfg = auto_scale_config(cfg, world)\n",
      "        \n",
      "        updated_config = os.path.join(os.getcwd(), \u001b[33m\"\u001b[39;49;00m\u001b[33mupdated_config.py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        cfg.dump(updated_config)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mFollowing config will be used for training:\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcfg.pretty_text\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mNotImplementedError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mDataset \u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.dataset\u001b[33m}\u001b[39;49;00m\u001b[33m is not implemented.\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\n",
      "\u001b[33m                                    Currently only COCO-style datasets are available.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "              \n",
      "    \u001b[34mreturn\u001b[39;49;00m updated_config\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mauto_scale_config\u001b[39;49;00m(cfg, world):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    Method automatically scales learning rate\u001b[39;49;00m\n",
      "\u001b[33m    based on number of processes in distributed cluster.\u001b[39;49;00m\n",
      "\u001b[33m    \u001b[39;49;00m\n",
      "\u001b[33m    When scaling, we take user-provided config as a config for single node with 8 GPUs\u001b[39;49;00m\n",
      "\u001b[33m    and scale it based on total number of training processes.\u001b[39;49;00m\n",
      "\u001b[33m    \u001b[39;49;00m\n",
      "\u001b[33m    Note, that batch size is not scaled, as MMDetection uses relative\u001b[39;49;00m\n",
      "\u001b[33m    batch size: cfg.data.samples_per_gpu\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      "    old_world_size = \u001b[34m8\u001b[39;49;00m \u001b[37m# Note, this is a hardcoded value, as MMDetection configs are build for single 8-GPU V100 node.\u001b[39;49;00m\n",
      "    old_lr = cfg.optimizer.lr\n",
      "    old_lr_warmup = cfg.lr_config.warmup_iters\n",
      "    scale = world[\u001b[33m\"\u001b[39;49;00m\u001b[33msize\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] / old_world_size\n",
      "    \n",
      "    cfg.optimizer.lr = old_lr * scale\n",
      "    cfg.lr_config.warmup_iters = old_lr_warmup / scale\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\u001b[33mInitial learning rate \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mold_lr\u001b[33m}\u001b[39;49;00m\u001b[33m and warmup \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mold_lr_warmup\u001b[33m}\u001b[39;49;00m\u001b[33m were scaled \u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\n",
      "\u001b[33m          to \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcfg.optimizer.lr\u001b[33m}\u001b[39;49;00m\u001b[33m and \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcfg.lr_config.warmup_iters\u001b[33m}\u001b[39;49;00m\u001b[33m respectively.\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m          Each GPU has batch size of \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcfg.data.samples_per_gpu\u001b[33m}\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m          Total number of GPUs in training cluster is \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mworld[\u001b[33m'\u001b[39;49;00m\u001b[33msize\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m          Effective batch size is \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcfg.data.samples_per_gpu * world[\u001b[33m'\u001b[39;49;00m\u001b[33msize\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[33m}\u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m cfg\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moptions_to_dict\u001b[39;49;00m(options):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    Takes string of options in format of 'key1=value1; key2=value2 ...'\u001b[39;49;00m\n",
      "\u001b[33m    and produces dictionary object {'key1': 'value1', 'key2':'value2'...}.\u001b[39;49;00m\n",
      "\u001b[33m    \u001b[39;49;00m\n",
      "\u001b[33m    It also supports lists of values: key3=v1,v2,v3.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      "    options_dict = \u001b[36mdict\u001b[39;49;00m(item.split(\u001b[33m\"\u001b[39;49;00m\u001b[33m=\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mfor\u001b[39;49;00m item \u001b[35min\u001b[39;49;00m options.split(\u001b[33m\"\u001b[39;49;00m\u001b[33m; \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)) \n",
      "    \n",
      "    \u001b[34mfor\u001b[39;49;00m key, value \u001b[35min\u001b[39;49;00m options_dict.items():\n",
      "        value = [_parse_int_float_bool(v) \u001b[34mfor\u001b[39;49;00m v \u001b[35min\u001b[39;49;00m value.split(\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)]\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(value) == \u001b[34m1\u001b[39;49;00m:\n",
      "            value = value[\u001b[34m0\u001b[39;49;00m]\n",
      "        options_dict[key] = value\n",
      "    \u001b[34mreturn\u001b[39;49;00m options_dict\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_int_float_bool\u001b[39;49;00m(val):\n",
      "    \u001b[34mtry\u001b[39;49;00m:\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mint\u001b[39;49;00m(val)\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m:\n",
      "        \u001b[34mpass\u001b[39;49;00m\n",
      "    \u001b[34mtry\u001b[39;49;00m:\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mfloat\u001b[39;49;00m(val)\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m:\n",
      "        \u001b[34mpass\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m val.lower() \u001b[35min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mtrue\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfalse\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]:\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[34mTrue\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m val.lower() == \u001b[33m'\u001b[39;49;00m\u001b[33mtrue\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m \u001b[34mFalse\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m val\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(config_path, work_dir, model_dir):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    This method copies model trained weights and config \u001b[39;49;00m\n",
      "\u001b[33m    from output directory to model directory.\u001b[39;49;00m\n",
      "\u001b[33m    Sagemaker then automatically archives content of model directory\u001b[39;49;00m\n",
      "\u001b[33m    and adds it to model registry once training job is completed.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      "\n",
      "    \u001b[37m# First copy config file\u001b[39;49;00m\n",
      "    \u001b[34mtry\u001b[39;49;00m:\n",
      "        new_config_path = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mconfig.py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        shutil.copyfile(config_path, new_config_path)\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mException when trying to copy \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mconfig_path\u001b[33m}\u001b[39;49;00m\u001b[33m to \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnew_config_path\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m(e)\n",
      "    \n",
      "    \n",
      "    \u001b[37m# Then copy checkpoints from work_dir\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m file \u001b[35min\u001b[39;49;00m os.listdir(work_dir):\n",
      "        \u001b[34mif\u001b[39;49;00m file.endswith(\u001b[33m\"\u001b[39;49;00m\u001b[33m.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\n",
      "            \u001b[34mtry\u001b[39;49;00m:\n",
      "                checkpoint_path = os.path.join(work_dir, file)\n",
      "                new_checkpoint_path = os.path.join(model_dir, file)\n",
      "                shutil.copyfile(checkpoint_path, new_checkpoint_path)\n",
      "            \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "                \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mException when trying to copy \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcheckpoint_path\u001b[33m}\u001b[39;49;00m\u001b[33m to \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnew_checkpoint_path\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "                \u001b[36mprint\u001b[39;49;00m(e)\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mModel config and checkpoints are saved to \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_dir\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    \n",
      "    \u001b[37m# Get initial configuration to select appropriate HuggingFace task and its configuration\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mStarting training...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser = ArgumentParser()\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--config-file\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[34mNone\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mFILE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "                        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly default MMDetection configs are supported now. \u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\n",
      "\u001b[33m                        See for details: https://github.com/open-mmlab/mmdetection/tree/master/configs/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--dataset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33mcoco\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mDefine which dataset format to use.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--options\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, nargs=\u001b[33m'\u001b[39;49;00m\u001b[33m+\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[34mNone\u001b[39;49;00m, help=\u001b[33m'\u001b[39;49;00m\u001b[33mConfig overrides.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--auto-scale\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[34mlambda\u001b[39;49;00m s: s.lower() \u001b[35min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mtrue\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33myes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], \n",
      "                        default=\u001b[34mFalse\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mwhether to scale batch parameters and learning rate based on cluster size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--validate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[34mlambda\u001b[39;49;00m s: s.lower() \u001b[35min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mtrue\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33myes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], \n",
      "                    default=\u001b[34mFalse\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mwhether to scale batch parameters and learning rate based on cluster size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \n",
      "    args, unknown = parser.parse_known_args()\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m args.options \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\n",
      "        args.options = options_to_dict(args.options[\u001b[34m0\u001b[39;49;00m])        \n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m unknown:\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mFollowing arguments were not recognized and won\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mt be used: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00munknown\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Derive parameters of distributed training cluster in Sagemaker\u001b[39;49;00m\n",
      "    world = get_training_world()  \n",
      "\n",
      "    \u001b[37m# Update config file\u001b[39;49;00m\n",
      "    config_file = training_configurator(args, world)\n",
      "              \n",
      "    \u001b[37m# Train script config\u001b[39;49;00m\n",
      "    launch_config = [ \u001b[33m\"\u001b[39;49;00m\u001b[33mpython -m torch.distributed.launch\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "                     \u001b[33m\"\u001b[39;49;00m\u001b[33m--nnodes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(world[\u001b[33m'\u001b[39;49;00m\u001b[33mnumber_of_machines\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]), \u001b[33m\"\u001b[39;49;00m\u001b[33m--node_rank\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(world[\u001b[33m'\u001b[39;49;00m\u001b[33mmachine_rank\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]),\n",
      "                     \u001b[33m\"\u001b[39;49;00m\u001b[33m--nproc_per_node\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(world[\u001b[33m'\u001b[39;49;00m\u001b[33mnumber_of_processes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]), \u001b[33m\"\u001b[39;49;00m\u001b[33m--master_addr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, world[\u001b[33m'\u001b[39;49;00m\u001b[33mmaster_addr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], \n",
      "                     \u001b[33m\"\u001b[39;49;00m\u001b[33m--master_port\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, world[\u001b[33m'\u001b[39;49;00m\u001b[33mmaster_port\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]]\n",
      " \n",
      "    train_config = [os.path.join(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMMDETECTION\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], \u001b[33m\"\u001b[39;49;00m\u001b[33mtools/train.py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \n",
      "                    config_file, \n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33m--launcher\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpytorch\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33m--work-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]]\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m args.validate:\n",
      "        train_config.append(\u001b[33m\"\u001b[39;49;00m\u001b[33m--no-validate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Concat Pytorch Distributed Launch config and MMdetection config\u001b[39;49;00m\n",
      "    joint_cmd = \u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.join(\u001b[36mstr\u001b[39;49;00m(x) \u001b[34mfor\u001b[39;49;00m x \u001b[35min\u001b[39;49;00m launch_config+train_config)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mFollowing command will be executed: \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, joint_cmd)\n",
      "    \n",
      "    process = subprocess.Popen(joint_cmd,  stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=\u001b[34mTrue\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[34mwhile\u001b[39;49;00m \u001b[34mTrue\u001b[39;49;00m:\n",
      "        output = process.stdout.readline()\n",
      "        \n",
      "        \u001b[34mif\u001b[39;49;00m process.poll() \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\n",
      "            \u001b[34mbreak\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m output:\n",
      "            \u001b[36mprint\u001b[39;49;00m(output.decode(\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).strip())\n",
      "    rc = process.poll()\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m process.returncode != \u001b[34m0\u001b[39;49;00m:\n",
      "        \u001b[34mraise\u001b[39;49;00m subprocess.CalledProcessError(returncode=process.returncode, cmd=joint_cmd)\n",
      "    \n",
      "    \u001b[37m# Before completing training, saving model artifacts\u001b[39;49;00m\n",
      "    save_model(config_file, os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    sys.exit(process.returncode)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "! pygmentize container_training/mmdetection_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "prefix_input = 'mmdetection-input'\n",
    "prefix_output = 'mmdetection-ouput'\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(account, region, container, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm parameters\n",
    "\n",
    "hyperparameters = {\n",
    "    \"config-file\" : \"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\", # config path is relative to MMDetection root directory\n",
    "    \"dataset\" : \"coco\",\n",
    "    \"auto-scale\" : \"false\", # whether to scale LR and Warm Up time\n",
    "    \"validate\" : \"true\", # whether to run validation after training is done\n",
    "    \n",
    "    # 'options' allows to override individual config values\n",
    "    \"options\" : \"total_epochs=12; optimizer.lr=0.08; evaluation.gpu_collect=True\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sagemaker will parse metrics from STDOUT and store/visualize them as part of training job\n",
    "metrics = [\n",
    "    {\n",
    "        \"Name\": \"loss\",\n",
    "        \"Regex\": \".*loss:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_rpn_cls\",\n",
    "        \"Regex\": \".*loss_rpn_cls:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_rpn_bbox\",\n",
    "        \"Regex\": \".*loss_rpn_bbox:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_cls\",\n",
    "        \"Regex\": \".*loss_cls:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"acc\",\n",
    "        \"Regex\": \".*acc:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_bbox\",\n",
    "        \"Regex\": \".*loss_bbox:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_mask\",\n",
    "        \"Regex\": \".*loss_mask:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"lr\",\n",
    "        \"Regex\": \"lr: (-?\\d+.?\\d*(?:[Ee]-\\d+)?)\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test training script and container locally\n",
    "\n",
    "\n",
    "Amazon SageMaker support [local mode](https://sagemaker.readthedocs.io/en/stable/overview.html?highlight=local%20mode#local-mode) which allows you to deploy and run training job locally first, before deploying your training container to remote SageMaker Training cluster.\n",
    "\n",
    "To use local mode, we first need to install some dependencies. Please note, you may or may not need to restart your kernel for this changes to be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker[local] in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.33.0)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.2.0)\n",
      "Requirement already satisfied: boto3>=1.16.32 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.17.35)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (20.9)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (3.7.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.1.5)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (20.3.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (3.15.2)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.1.5)\n",
      "Requirement already satisfied: docker-compose>=1.25.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.28.6)\n",
      "Requirement already satisfied: urllib3!=1.25,!=1.25.1,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.26.3)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (5.4.1)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.35 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (1.20.35)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (0.3.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.35->boto3>=1.16.32->sagemaker[local]) (2.8.1)\n",
      "Requirement already satisfied: docker[ssh]<5,>=4.4.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (4.4.4)\n",
      "Requirement already satisfied: dockerpty<1,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.4.1)\n",
      "Requirement already satisfied: docopt<1,>=0.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.6.2)\n",
      "Requirement already satisfied: python-dotenv<1,>=0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.15.0)\n",
      "Requirement already satisfied: distro<2,>=1.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.5.0)\n",
      "Requirement already satisfied: jsonschema<4,>=2.5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: websocket-client<1,>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.58.0)\n",
      "Requirement already satisfied: texttable<2,>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.6.3)\n",
      "Requirement already satisfied: cached-property<2,>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (2.25.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker[ssh]<5,>=4.4.4->docker-compose>=1.25.2->sagemaker[local]) (1.15.0)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker[ssh]<5,>=4.4.4->docker-compose>=1.25.2->sagemaker[local]) (2.7.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]) (3.4.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jsonschema<4,>=2.5.1->docker-compose>=1.25.2->sagemaker[local]) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jsonschema<4,>=2.5.1->docker-compose>=1.25.2->sagemaker[local]) (0.17.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker[local]) (2.4.7)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker[ssh]<5,>=4.4.4->docker-compose>=1.25.2->sagemaker[local]) (1.4.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker[ssh]<5,>=4.4.4->docker-compose>=1.25.2->sagemaker[local]) (3.4.4)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker[ssh]<5,>=4.4.4->docker-compose>=1.25.2->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker[ssh]<5,>=4.4.4->docker-compose>=1.25.2->sagemaker[local]) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker[ssh]<5,>=4.4.4->docker-compose>=1.25.2->sagemaker[local]) (2.20)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.20.0->docker-compose>=1.25.2->sagemaker[local]) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.20.0->docker-compose>=1.25.2->sagemaker[local]) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.20.0->docker-compose>=1.25.2->sagemaker[local]) (2020.12.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->sagemaker[local]) (2021.1)\n"
     ]
    }
   ],
   "source": [
    "# Install all dependecies for local run. \n",
    "# Note you may need to restart your Sagemaker Notebook kernel to have changes applied.\n",
    "! pip install 'sagemaker[local]' --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.local import LocalSession\n",
    "\n",
    "# Configure our local training session\n",
    "sagemaker_local_session = LocalSession()\n",
    "sagemaker_local_session.config = {'local': {'local_code': True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../coco2017’: File exists\n",
      "download: s3://mzanur-coco/coco/annotations/captions_val2017.json to ../coco2017/annotations/captions_val2017.json\n",
      "download: s3://mzanur-coco/coco/annotations/person_keypoints_val2017.json to ../coco2017/annotations/person_keypoints_val2017.json\n",
      "download: s3://mzanur-coco/coco/annotations/instances_val2017.json to ../coco2017/annotations/instances_val2017.json\n",
      "download: s3://mzanur-coco/coco/train2017/000000000009.jpg to ../coco2017/train2017/000000000009.jpg\n",
      "download: s3://mzanur-coco/coco/train2017/000000000025.jpg to ../coco2017/train2017/000000000025.jpg\n",
      "download: s3://mzanur-coco/coco/annotations/captions_train2017.json to ../coco2017/annotations/captions_train2017.json\n",
      "download: s3://mzanur-coco/coco/train2017/000000000030.jpg to ../coco2017/train2017/000000000030.jpg\n",
      "download: s3://mzanur-coco/coco/train2017/000000000034.jpg to ../coco2017/train2017/000000000034.jpg\n",
      "download: s3://mzanur-coco/coco/train2017/000000000036.jpg to ../coco2017/train2017/000000000036.jpg\n",
      "download: s3://mzanur-coco/coco/train2017/000000000042.jpg to ../coco2017/train2017/000000000042.jpg\n",
      "^Cmpleted 574.5 MiB/~1.2 GiB (111.7 MiB/s) with ~945 file(s) remaining (calculating...)\n",
      "download: s3://mzanur-coco/coco/train2017/000000000061.jpg to ../coco2017/train2017/000000000061.jpg\n",
      "cancelled: ctrl-c received                                                             \n"
     ]
    }
   ],
   "source": [
    "# Copy training data locally\n",
    "! mkdir ../coco2017\n",
    "! aws s3 cp s3://mzanur-pt/coco/ ../coco2017 --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to run our training container locally. For this, we need to pass special type of instance `local_gpu`. In this case, SageMaker will run training container with access to CUDA devices. Note, if you don't need access to GPUs, you may choose `local` instance type.\n",
    "\n",
    "Note, depending on configuration of your local host and available memory, you may run into memory issues when loading dataset. In this case, try reducing your batch size to bring down memory consumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating r1fh0lfsso-algo-1-nxna5 ... \n",
      "Creating r1fh0lfsso-algo-1-nxna5 ... done\n",
      "Attaching to r1fh0lfsso-algo-1-nxna5\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,455 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,487 sagemaker-training-toolkit INFO     Failed to parse hyperparameter config-file value configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py to Json.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,487 sagemaker-training-toolkit INFO     Failed to parse hyperparameter dataset value coco to Json.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,487 sagemaker-training-toolkit INFO     Failed to parse hyperparameter options value total_epochs=12; optimizer.lr=0.08; evaluation.gpu_collect=True to Json.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,509 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,512 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,543 sagemaker-training-toolkit INFO     Failed to parse hyperparameter config-file value configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py to Json.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,543 sagemaker-training-toolkit INFO     Failed to parse hyperparameter dataset value coco to Json.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,543 sagemaker-training-toolkit INFO     Failed to parse hyperparameter options value total_epochs=12; optimizer.lr=0.08; evaluation.gpu_collect=True to Json.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,584 sagemaker-training-toolkit INFO     Failed to parse hyperparameter config-file value configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py to Json.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,585 sagemaker-training-toolkit INFO     Failed to parse hyperparameter dataset value coco to Json.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,585 sagemaker-training-toolkit INFO     Failed to parse hyperparameter options value total_epochs=12; optimizer.lr=0.08; evaluation.gpu_collect=True to Json.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,626 sagemaker-training-toolkit INFO     Failed to parse hyperparameter config-file value configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py to Json.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,626 sagemaker-training-toolkit INFO     Failed to parse hyperparameter dataset value coco to Json.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,626 sagemaker-training-toolkit INFO     Failed to parse hyperparameter options value total_epochs=12; optimizer.lr=0.08; evaluation.gpu_collect=True to Json.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:26,637 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Training Env:\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m {\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     },\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"current_host\": \"algo-1-nxna5\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         \"algo-1-nxna5\"\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     ],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         \"config-file\": \"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         \"dataset\": \"coco\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         \"auto-scale\": false,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         \"validate\": true,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         \"options\": \"total_epochs=12; optimizer.lr=0.08; evaluation.gpu_collect=True\"\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     },\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         \"training\": {\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         }\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     },\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"job_name\": \"mzanur-mmdetection-training-2021-04-09-01-07-23-959\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"master_hostname\": \"algo-1-nxna5\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"module_name\": \"mmdetection_train\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"num_cpus\": 32,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"num_gpus\": 4,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         \"current_host\": \"algo-1-nxna5\",\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             \"algo-1-nxna5\"\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         ]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     },\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     \"user_entry_point\": \"mmdetection_train.py\"\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m }\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Environment variables:\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_HOSTS=[\"algo-1-nxna5\"]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_HPS={\"auto-scale\":false,\"config-file\":\"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\"dataset\":\"coco\",\"options\":\"total_epochs=12; optimizer.lr=0.08; evaluation.gpu_collect=True\",\"validate\":true}\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_USER_ENTRY_POINT=mmdetection_train.py\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-nxna5\",\"hosts\":[\"algo-1-nxna5\"]}\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_CURRENT_HOST=algo-1-nxna5\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_MODULE_NAME=mmdetection_train\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_NUM_CPUS=32\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_NUM_GPUS=4\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-nxna5\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-nxna5\"],\"hyperparameters\":{\"auto-scale\":false,\"config-file\":\"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\"dataset\":\"coco\",\"options\":\"total_epochs=12; optimizer.lr=0.08; evaluation.gpu_collect=True\",\"validate\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mzanur-mmdetection-training-2021-04-09-01-07-23-959\",\"log_level\":20,\"master_hostname\":\"algo-1-nxna5\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"mmdetection_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-nxna5\",\"hosts\":[\"algo-1-nxna5\"]},\"user_entry_point\":\"mmdetection_train.py\"}\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_USER_ARGS=[\"--auto-scale\",\"False\",\"--config-file\",\"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\"--dataset\",\"coco\",\"--options\",\"total_epochs=12; optimizer.lr=0.08; evaluation.gpu_collect=True\",\"--validate\",\"True\"]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_HP_CONFIG-FILE=configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_HP_DATASET=coco\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_HP_AUTO-SCALE=false\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_HP_VALIDATE=true\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m SM_HP_OPTIONS=total_epochs=12; optimizer.lr=0.08; evaluation.gpu_collect=True\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages:/opt/ml/code/mmcv:/opt/ml/code/mmdetection\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m /opt/conda/bin/python3.6 mmdetection_train.py --auto-scale False --config-file configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py --dataset coco --options total_epochs=12; optimizer.lr=0.08; evaluation.gpu_collect=True --validate True\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Starting training...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Following config will be used for training:model = dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     type='MaskRCNN',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     pretrained='torchvision://resnet50',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     backbone=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         type='ResNet',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         depth=50,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         num_stages=4,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         out_indices=(0, 1, 2, 3),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         frozen_stages=1,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         norm_cfg=dict(type='BN', requires_grad=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         norm_eval=True,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         style='pytorch'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     neck=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         type='FPN',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         in_channels=[256, 512, 1024, 2048],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         out_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         num_outs=5),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     rpn_head=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         type='RPNHead',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         in_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         feat_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         anchor_generator=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             type='AnchorGenerator',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             scales=[8],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             ratios=[0.5, 1.0, 2.0],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             strides=[4, 8, 16, 32, 64]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         bbox_coder=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             type='DeltaXYWHBBoxCoder',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         loss_cls=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     roi_head=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         type='StandardRoIHead',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         bbox_roi_extractor=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             type='SingleRoIExtractor',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             out_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             featmap_strides=[4, 8, 16, 32]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         bbox_head=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             type='Shared2FCBBoxHead',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             in_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             fc_out_channels=1024,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             roi_feat_size=7,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             num_classes=80,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             bbox_coder=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 type='DeltaXYWHBBoxCoder',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             reg_class_agnostic=False,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             loss_cls=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         mask_roi_extractor=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             type='SingleRoIExtractor',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             out_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             featmap_strides=[4, 8, 16, 32]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         mask_head=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             type='FCNMaskHead',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             num_convs=4,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             in_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             conv_out_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             num_classes=80,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             loss_mask=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     train_cfg=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         rpn=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             assigner=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 type='MaxIoUAssigner',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 pos_iou_thr=0.7,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 neg_iou_thr=0.3,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 min_pos_iou=0.3,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 match_low_quality=True,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 ignore_iof_thr=-1),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             sampler=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 type='RandomSampler',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 num=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 pos_fraction=0.5,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 neg_pos_ub=-1,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 add_gt_as_proposals=False),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             allowed_border=-1,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             pos_weight=-1,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             debug=False),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         rpn_proposal=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             nms_pre=2000,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             max_per_img=1000,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             nms=dict(type='nms', iou_threshold=0.7),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             min_bbox_size=0),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         rcnn=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             assigner=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 type='MaxIoUAssigner',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 pos_iou_thr=0.5,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 neg_iou_thr=0.5,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 min_pos_iou=0.5,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 match_low_quality=True,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 ignore_iof_thr=-1),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             sampler=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 type='RandomSampler',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 num=512,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 pos_fraction=0.25,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 neg_pos_ub=-1,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 add_gt_as_proposals=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             mask_size=28,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             pos_weight=-1,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             debug=False)),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     test_cfg=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         rpn=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             nms_pre=1000,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             max_per_img=1000,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             nms=dict(type='nms', iou_threshold=0.7),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             min_bbox_size=0),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         rcnn=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             score_thr=0.05,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             nms=dict(type='nms', iou_threshold=0.5),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             max_per_img=100,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             mask_thr_binary=0.5)))\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dataset_type = 'CocoDataset'\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m data_root = '/opt/ml/input/data/training'\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m img_norm_cfg = dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m train_pipeline = [\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     dict(type='LoadImageFromFile'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     dict(type='RandomFlip', flip_ratio=0.5),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         type='Normalize',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         mean=[123.675, 116.28, 103.53],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         std=[58.395, 57.12, 57.375],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         to_rgb=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     dict(type='Pad', size_divisor=32),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     dict(type='DefaultFormatBundle'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m test_pipeline = [\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     dict(type='LoadImageFromFile'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         type='MultiScaleFlipAug',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         img_scale=(1333, 800),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         flip=False,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         transforms=[\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='Resize', keep_ratio=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='RandomFlip'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 type='Normalize',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 mean=[123.675, 116.28, 103.53],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 std=[58.395, 57.12, 57.375],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 to_rgb=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='Pad', size_divisor=32),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='ImageToTensor', keys=['img']),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='Collect', keys=['img'])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         ])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m data = dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     samples_per_gpu=2,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     workers_per_gpu=2,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     train=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         type='CocoDataset',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         ann_file=\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         '/opt/ml/input/data/training/annotations/instances_train2017.json',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         img_prefix='/opt/ml/input/data/training/train2017',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         pipeline=[\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='LoadImageFromFile'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='RandomFlip', flip_ratio=0.5),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 type='Normalize',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 mean=[123.675, 116.28, 103.53],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 std=[58.395, 57.12, 57.375],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 to_rgb=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='Pad', size_divisor=32),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='DefaultFormatBundle'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 type='Collect',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         ]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     val=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         type='CocoDataset',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         ann_file=\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         '/opt/ml/input/data/training/annotations/instances_val2017.json',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         img_prefix='/opt/ml/input/data/training/val2017',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         pipeline=[\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='LoadImageFromFile'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 type='MultiScaleFlipAug',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 img_scale=(1333, 800),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 flip=False,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 transforms=[\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                     dict(type='Resize', keep_ratio=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                     dict(type='RandomFlip'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                     dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                         type='Normalize',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                         mean=[123.675, 116.28, 103.53],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                         std=[58.395, 57.12, 57.375],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                         to_rgb=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                     dict(type='Pad', size_divisor=32),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                     dict(type='ImageToTensor', keys=['img']),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                     dict(type='Collect', keys=['img'])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 ])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         ]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     test=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         type='CocoDataset',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         ann_file=\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         '/opt/ml/input/data/training/annotations/instances_val2017.json',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         img_prefix='/opt/ml/input/data/training/val2017',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         pipeline=[\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(type='LoadImageFromFile'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m             dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 type='MultiScaleFlipAug',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 img_scale=(1333, 800),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 flip=False,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 transforms=[\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                     dict(type='Resize', keep_ratio=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                     dict(type='RandomFlip'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                     dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                         type='Normalize',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                         mean=[123.675, 116.28, 103.53],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                         std=[58.395, 57.12, 57.375],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                         to_rgb=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                     dict(type='Pad', size_divisor=32),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                     dict(type='ImageToTensor', keys=['img']),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                     dict(type='Collect', keys=['img'])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m                 ])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m         ]))\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m evaluation = dict(metric=['bbox', 'segm'], gpu_collect=True)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m optimizer = dict(type='SGD', lr=0.08, momentum=0.9, weight_decay=0.0001)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m optimizer_config = dict(grad_clip=None)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m lr_config = dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     policy='step',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     warmup='linear',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     warmup_iters=500,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     warmup_ratio=0.001,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m     step=[8, 11])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m checkpoint_config = dict(interval=1)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dist_params = dict(backend='nccl')\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m log_level = 'INFO'\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m load_from = None\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m resume_from = None\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m workflow = [('train', 1)]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m total_epochs = 12\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Following command will be executed: \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m  python -m torch.distributed.launch --nnodes 1 --node_rank 0 --nproc_per_node 4 --master_addr algo-1-nxna5 --master_port 55555 /opt/ml/code/mmdetection/tools/train.py /opt/ml/code/updated_config.py --launcher pytorch --work-dir /opt/ml/output/data\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m *****************************************\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m *****************************************\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m fatal: Not a git repository (or any of the parent directories): .git\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m fatal: Not a git repository (or any of the parent directories): .git\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m fatal: Not a git repository (or any of the parent directories): .git\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m fatal: Not a git repository (or any of the parent directories): .git\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:35,477 - mmdet - INFO - Environment info:\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ------------------------------------------------------------\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m sys.platform: linux\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Python: 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m CUDA available: True\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m GPU 0,1,2,3: Tesla V100-SXM2-16GB\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m CUDA_HOME: /usr/local/cuda\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m GCC: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m PyTorch: 1.6.0\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m PyTorch compiling details: PyTorch built with:\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - GCC 5.4\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - C++ Version: 201402\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - OpenMP 201307 (a.k.a. OpenMP 4.0)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - NNPACK is enabled\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - CPU capability usage: AVX2\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - CUDA Runtime 10.1\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - NVCC architecture flags: -gencode;arch=compute_35,code=sm_35;-gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_70,code=compute_70\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - CuDNN 7.6.5\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - Built with CuDNN 7.6.3\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - Magma 2.5.2\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format, FORCE_FALLBACK_CUDA_MPI=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=ON, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m TorchVision: 0.7.0+cu101\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m OpenCV: 3.4.2\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m MMCV: 1.3.0\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m MMCV Compiler: GCC 5.4\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m MMCV CUDA Compiler: 10.1\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m MMDetection: 2.11.0+\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ------------------------------------------------------------\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:36,535 - mmdet - INFO - Distributed training: True\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:37,581 - mmdet - INFO - Config:\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m model = dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='MaskRCNN',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m pretrained='torchvision://resnet50',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m backbone=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='ResNet',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m depth=50,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m num_stages=4,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m out_indices=(0, 1, 2, 3),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m frozen_stages=1,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m norm_cfg=dict(type='BN', requires_grad=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m norm_eval=True,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m style='pytorch'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m neck=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='FPN',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m in_channels=[256, 512, 1024, 2048],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m out_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m num_outs=5),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m rpn_head=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='RPNHead',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m in_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m feat_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m anchor_generator=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='AnchorGenerator',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m scales=[8],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ratios=[0.5, 1.0, 2.0],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m strides=[4, 8, 16, 32, 64]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m bbox_coder=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='DeltaXYWHBBoxCoder',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loss_cls=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m roi_head=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='StandardRoIHead',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m bbox_roi_extractor=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='SingleRoIExtractor',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m out_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m featmap_strides=[4, 8, 16, 32]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m bbox_head=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='Shared2FCBBoxHead',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m in_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m fc_out_channels=1024,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m roi_feat_size=7,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m num_classes=80,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m bbox_coder=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='DeltaXYWHBBoxCoder',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m reg_class_agnostic=False,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loss_cls=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m mask_roi_extractor=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='SingleRoIExtractor',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m out_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m featmap_strides=[4, 8, 16, 32]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m mask_head=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='FCNMaskHead',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m num_convs=4,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m in_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m conv_out_channels=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m num_classes=80,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loss_mask=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m train_cfg=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m rpn=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m assigner=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='MaxIoUAssigner',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m pos_iou_thr=0.7,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m neg_iou_thr=0.3,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m min_pos_iou=0.3,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m match_low_quality=True,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ignore_iof_thr=-1),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m sampler=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='RandomSampler',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m num=256,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m pos_fraction=0.5,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m neg_pos_ub=-1,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m add_gt_as_proposals=False),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m allowed_border=-1,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m pos_weight=-1,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m debug=False),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m rpn_proposal=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m nms_pre=2000,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m max_per_img=1000,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m nms=dict(type='nms', iou_threshold=0.7),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m min_bbox_size=0),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m rcnn=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m assigner=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='MaxIoUAssigner',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m pos_iou_thr=0.5,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m neg_iou_thr=0.5,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m min_pos_iou=0.5,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m match_low_quality=True,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ignore_iof_thr=-1),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m sampler=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='RandomSampler',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m num=512,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m pos_fraction=0.25,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m neg_pos_ub=-1,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m add_gt_as_proposals=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m mask_size=28,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m pos_weight=-1,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m debug=False)),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m test_cfg=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m rpn=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m nms_pre=1000,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m max_per_img=1000,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m nms=dict(type='nms', iou_threshold=0.7),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m min_bbox_size=0),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m rcnn=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m score_thr=0.05,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m nms=dict(type='nms', iou_threshold=0.5),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m max_per_img=100,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m mask_thr_binary=0.5)))\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dataset_type = 'CocoDataset'\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m data_root = '/opt/ml/input/data/training'\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m img_norm_cfg = dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m train_pipeline = [\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='LoadImageFromFile'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='RandomFlip', flip_ratio=0.5),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='Normalize',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m mean=[123.675, 116.28, 103.53],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m std=[58.395, 57.12, 57.375],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m to_rgb=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Pad', size_divisor=32),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='DefaultFormatBundle'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m test_pipeline = [\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='LoadImageFromFile'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='MultiScaleFlipAug',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m img_scale=(1333, 800),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m flip=False,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m transforms=[\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Resize', keep_ratio=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='RandomFlip'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='Normalize',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m mean=[123.675, 116.28, 103.53],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m std=[58.395, 57.12, 57.375],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m to_rgb=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Pad', size_divisor=32),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='ImageToTensor', keys=['img']),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Collect', keys=['img'])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m data = dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m samples_per_gpu=2,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m workers_per_gpu=2,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m train=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='CocoDataset',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ann_file=\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m '/opt/ml/input/data/training/annotations/instances_train2017.json',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m img_prefix='/opt/ml/input/data/training/train2017',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m pipeline=[\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='LoadImageFromFile'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='RandomFlip', flip_ratio=0.5),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='Normalize',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m mean=[123.675, 116.28, 103.53],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m std=[58.395, 57.12, 57.375],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m to_rgb=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Pad', size_divisor=32),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='DefaultFormatBundle'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='Collect',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m val=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='CocoDataset',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ann_file=\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m '/opt/ml/input/data/training/annotations/instances_val2017.json',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m img_prefix='/opt/ml/input/data/training/val2017',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m pipeline=[\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='LoadImageFromFile'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='MultiScaleFlipAug',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m img_scale=(1333, 800),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m flip=False,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m transforms=[\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Resize', keep_ratio=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='RandomFlip'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='Normalize',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m mean=[123.675, 116.28, 103.53],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m std=[58.395, 57.12, 57.375],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m to_rgb=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Pad', size_divisor=32),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='ImageToTensor', keys=['img']),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Collect', keys=['img'])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ]),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m test=dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='CocoDataset',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ann_file=\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m '/opt/ml/input/data/training/annotations/instances_val2017.json',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m img_prefix='/opt/ml/input/data/training/val2017',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m pipeline=[\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='LoadImageFromFile'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='MultiScaleFlipAug',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m img_scale=(1333, 800),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m flip=False,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m transforms=[\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Resize', keep_ratio=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='RandomFlip'),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m type='Normalize',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m mean=[123.675, 116.28, 103.53],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m std=[58.395, 57.12, 57.375],\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m to_rgb=True),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Pad', size_divisor=32),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='ImageToTensor', keys=['img']),\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dict(type='Collect', keys=['img'])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m ]))\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m evaluation = dict(metric=['bbox', 'segm'], gpu_collect=True)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m optimizer = dict(type='SGD', lr=0.08, momentum=0.9, weight_decay=0.0001)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m optimizer_config = dict(grad_clip=None)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m lr_config = dict(\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m policy='step',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m warmup='linear',\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m warmup_iters=500,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m warmup_ratio=0.001,\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m step=[8, 11])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m checkpoint_config = dict(interval=1)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m dist_params = dict(backend='nccl')\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m log_level = 'INFO'\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m load_from = None\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m resume_from = None\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m workflow = [('train', 1)]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m total_epochs = 12\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m work_dir = '/opt/ml/output/data'\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m gpu_ids = range(0, 4)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:38,135 - mmdet - INFO - load model from: torchvision://resnet50\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:38,135 - mmdet - INFO - Use load_from_torchvision loader\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 122MB/s]]00/97.8M [00:00<?, ?B/s]\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m NCCL version 2.4.8+cuda10.1\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:07:41,142 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m \n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loading annotations into memory...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loading annotations into memory...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loading annotations into memory...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loading annotations into memory...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Done (t=15.39s)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m creating index...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Done (t=15.25s)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m creating index...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Done (t=15.32s)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m creating index...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Done (t=15.40s)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m creating index...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m index created!\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m index created!\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m index created!\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m index created!\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m fatal: Not a git repository (or any of the parent directories): .git\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m fatal: Not a git repository (or any of the parent directories): .git\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m fatal: Not a git repository (or any of the parent directories): .git\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m fatal: Not a git repository (or any of the parent directories): .git\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loading annotations into memory...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loading annotations into memory...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loading annotations into memory...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m loading annotations into memory...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Done (t=0.51s)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m creating index...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Done (t=0.52s)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m creating index...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Done (t=0.51s)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m creating index...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m Done (t=0.52s)\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m creating index...\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m index created!\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m index created!\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m index created!\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m index created!\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:08:01,711 - mmdet - INFO - Start running, host: root@algo-1-nxna5, work_dir: /opt/ml/output/data\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:08:01,711 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m 2021-04-09 01:09:04,677 - mmdet - INFO - Epoch [1][50/14659]\tlr: 7.912e-03, eta: 2 days, 13:29:21, time: 1.259, data_time: 0.916, memory: 4016, loss_rpn_cls: 0.4261, loss_rpn_bbox: 0.1144, loss_cls: 0.9679, acc: 88.6191, loss_bbox: 0.1173, loss_mask: 0.7361, loss: 2.3618\n",
      "\u001b[36mr1fh0lfsso-algo-1-nxna5 |\u001b[0m INFO:mmdet:Epoch [1][50/14659]\tlr: 7.912e-03, eta: 2 days, 13:29:21, time: 1.259, data_time: 0.916, memory: 4016, loss_rpn_cls: 0.4261, loss_rpn_bbox: 0.1144, loss_cls: 0.9679, acc: 88.6191, loss_bbox: 0.1173, loss_mask: 0.7361, loss: 2.3618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmp9bcj7hbm/algo-1-nxna5 Please remove it manually.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e02d6c753b6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"training\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"file:///home/ec2-user/SageMaker/sagemaker_examples/coco2017\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# may need to increase shm for local mode - https://github.com/aws/sagemaker-python-sdk/issues/937\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# sudo service docker restart on AL1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \"\"\"\n\u001b[1;32m   1431\u001b[0m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     def _get_train_request(  # noqa: C901\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;31m# _stream_output() doesn't have the command line. We will handle the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "est = sagemaker.estimator.Estimator(image,\n",
    "                                    role=role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='local_gpu',\n",
    "                                    output_path=\"s3://{}/{}\".format(bucket, prefix_output),\n",
    "                                    metric_definitions = metrics,\n",
    "                                    hyperparameters = hyperparameters, \n",
    "                                    sagemaker_session=sagemaker_local_session\n",
    ")\n",
    "\n",
    "est.fit({\"training\" : \"file:///home/ec2-user/SageMaker/sagemaker_examples/coco2017\"})\n",
    "# may need to increase shm for local mode - https://github.com/aws/sagemaker-python-sdk/issues/937\n",
    "# sudo service docker restart on AL1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Sagemaker Training \n",
    "\n",
    "Now that we tested our training scrip and container locally, we are ready to run training job on disrtibuted SageMaker training cluster. Execute cell below to start training on Sagemaker. Note, that you have available parameters such as `instance_count` and `instance_type` to manage your training cluster configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = 'ml.p3.16xlarge'\n",
    "instance_count = 2\n",
    "\n",
    "est = sagemaker.estimator.Estimator(image,\n",
    "                                          role=role,\n",
    "                                          instance_count=instance_count,\n",
    "                                          instance_type=instance_type,\n",
    "                                          volume_size=100,\n",
    "                                          output_path=\"s3://{}/{}\".format(bucket, prefix_output),\n",
    "                                          metric_definitions = metrics,\n",
    "                                          hyperparameters = hyperparameters, \n",
    "                                          sagemaker_session=session\n",
    ")\n",
    "\n",
    "est.fit({\"training\" : \"s3://mzanur-pt/coco\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
